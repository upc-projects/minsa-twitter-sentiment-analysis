import numpy as np
import tensorflow as tf
from tensorflow import keras
from utils import preprocess_text
from keras.preprocessing.sequence import pad_sequences
import pickle

#Import model from saved model
#The model folder should be in root
model = keras.models.load_model('cnn_model1')

#Set max sequence length
MAX_SEQUENCE_LENGTH = 50

#Get the tokenizer from saved pickle file
with open('tokenizer.pickle', 'rb') as handle:
    tokenizer = pickle.load(handle)

#Set text to try the model predictions
text = [
    "Partido complicado pero no perdido. Saldremos de esta ğŸ’ª Que la fe sea lo ultimo que se pierda ğŸ™Œ",
    "@manuval68 @Minsa_Peru @Agencia_Andina @noticias_tvperu @RadioNacionalFM @DiarioElPeruano ASI ES!!!!!!!!!!!!!!!!!!!! MALDITAS FUJUIRRAATAAAAAASSSS!!!!!!!!!!!!!!!! #FujimoristasEnemigosDelPeru!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!",
    "@Minsa_Peru @Agencia_Andina @noticias_tvperu @RadioNacionalFM @DiarioElPeruano Cuidence por favor !!!!!!!!! distanciamiento fisico ! â¤ï¸â¤ï¸â¤ï¸â¤ï¸ğŸ™ğŸ¤ğŸ’ª tomen distancia ğŸ¥º",
    "@rparrawong @Minsa_Peru Tienen el numero de contagios de hoy y fallecidos por regiones please?? ğŸ™",
    "Partido complicado pero no perdido. Saldremos de esta ğŸ’ª Que la fe sea lo ultimo que se pierda ğŸ™Œ",
    "El chino es un buen puto, me cae bien",
    "@pcmperu @nlcr5_ @presidenciaperu @PeruPaisDigital @MTC_GobPeru @Minsa_Peru @EsSaludPeru @elcomercio_peru @larepublica_pe @RPPNoticias @canalN_ @exitosape Otra cojudez de este gobierno incompetente"
]

#Process the model
text = [preprocess_text(t) for t in text]
print(text)
text = tokenizer.texts_to_sequences(text)
text = pad_sequences(text, maxlen=MAX_SEQUENCE_LENGTH)

predictions = model.predict(text)
for p in predictions:
    p = [round(num,5) for num in p]
    print(p)